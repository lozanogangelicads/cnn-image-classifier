{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01375c32",
   "metadata": {
    "id": "01375c32"
   },
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Applied Machine Learning\n",
    "\n",
    "## Name:Angelica LOZANO GOMEZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b249b051",
   "metadata": {
    "id": "b249b051"
   },
   "source": [
    "### Overview\n",
    "\n",
    "The [`CIFAR10` dataset](https://keras.io/api/datasets/cifar10/) contains 50,000 32 $\\times$ 32 colored images of the things listed below. \n",
    "\n",
    "| Label    | Description |\n",
    "| -------- | -------|\n",
    "| 0 | airplane    |\n",
    "| 1 | automobile     |\n",
    "| 2 | bird    |\n",
    "| 3 | cat    |\n",
    "| 4 | deer    |\n",
    "| 5 | dog    |\n",
    "| 6 | frog    |\n",
    "| 7 | horse    |\n",
    "| 8 | ship    |\n",
    "| 9 | truck    |\n",
    "\n",
    "The `base_model` contains a CNN that was trained on over 17,000 CIFAR10 images, none of which contained a horse, ship, or truck. In this assignment, you will use the bottleneck layers of the `base_model`, along with transfer learning to build a network that can classify all 10 categories of the images in the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce8065-0981-41dc-b06e-1e52b8a974c8",
   "metadata": {},
   "source": [
    "### Install Tensorflow 2.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f940fab-8cc5-49ab-a18c-f589c92bdf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/angelicalozano/anaconda3/envs/tf_env/lib/python3.8/site-packages (25.0.1)\n",
      "Pip updated!\n",
      "TensorFlow version 2.9.2 is already installed.\n",
      "Please restart your kernel to apply the changes.\n"
     ]
    }
   ],
   "source": [
    "# CODE\n",
    "import subprocess\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "def update_libraries():\n",
    "    tf_desired_version = \"2.9.2\"\n",
    "\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        tf_installed_version = tf.__version__\n",
    "    except ImportError:\n",
    "        tf_installed_version = None\n",
    "\n",
    "    # Update pip to the latest version\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip'])\n",
    "    print(\"Pip updated!\")\n",
    "    \n",
    "    #Check for the right version\n",
    "    if tf_installed_version != tf_desired_version:\n",
    "        print(f\"Current TensorFlow version: {tf_installed_version}. Installing version {tf_desired_version}...\")\n",
    "        \n",
    "        # Uninstall the current TensorFlow version\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'uninstall', '-y', 'tensorflow'])\n",
    "        \n",
    "        # Install the desired TensorFlow version\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', f'tensorflow=={tf_desired_version}'])\n",
    "\n",
    "        clear_output()\n",
    "        print(\"TensorFlow version {tf_desired_version} installed successfully\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"TensorFlow version {tf_desired_version} is already installed.\")    \n",
    "\n",
    "\n",
    "    print(f\"Please restart your kernel to apply the changes.\")\n",
    "    \n",
    "update_libraries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "671e354a",
   "metadata": {
    "id": "671e354a"
   },
   "outputs": [],
   "source": [
    "# common imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824bea7e",
   "metadata": {
    "id": "824bea7e"
   },
   "source": [
    "### Data and Model Prep\n",
    "\n",
    "Load the `base_model` and then run the following cell to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d50001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 22:30:05.816380: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-18 22:30:05.816786: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# CODE\n",
    "from tensorflow.keras.models import load_model\n",
    "base_model = load_model('base_model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE -- takes almost 3 minutes to run\n",
    "x_train = np.loadtxt('data/x_train.txt').reshape(32516, 32, 32, 3)\n",
    "y_train = np.loadtxt('data/y_train.txt')\n",
    "x_test = np.loadtxt('data/x_test.txt').reshape(6512, 32, 32, 3)\n",
    "y_test = np.loadtxt('data/y_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e5e73",
   "metadata": {},
   "source": [
    "Let's test the `base_model`. The below code loads and displays a sample image of a ship from the test dataset. Use the `base_model` to make a prediction about the object contained in the sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "x = x_test[0]\n",
    "\n",
    "print(y_test[0])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# preprocess the image\n",
    "x = image.img_to_array(x_test[0])\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# CODE\n",
    "from tensorflow.keras.models import Model\n",
    "model = Model(inputs=base_model.layers[0].input, outputs=base_model.layers[3].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0ffe1",
   "metadata": {},
   "source": [
    "What does the `base_model` predict that the sample image is? Let's use transfer learning to create a domain-specific model that can classify images of horses, ships, and trucks in addition to the rest of the images that the `base_model` was trained on.\n",
    "\n",
    "The below code extracts the bottleneck layers from the `base_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model(inputs = base_model.layers[0].input, outputs = base_model.layers[3].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aeeb92",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Create the classification layers for transfer learning and train them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "# Input shape is the output of the CNN model (6, 6, 64)\n",
    "classification_input = Input(shape=(6, 6, 64))\n",
    "x = layers.Flatten()(classification_input)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "classification_output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "classification = Model(inputs=classification_input, outputs=classification_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "classification.compile(optimizer='adam',\n",
    "                       loss='sparse_categorical_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a60561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE -- takes about 2 minutes to run\n",
    "# First get the features from the CNN model\n",
    "features_train = model.predict(x_train)\n",
    "\n",
    "# Then train the classifier on these features\n",
    "history = classification.fit(features_train, y_train,\n",
    "                             epochs=10,\n",
    "                             batch_size=64,\n",
    "                             validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c9aa0",
   "metadata": {},
   "source": [
    "Plot the training and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b409b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CODE\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab116c",
   "metadata": {},
   "source": [
    "Check to ensure the new model correctly classifies the sample image of a ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf42c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Reload and preprocess the sample image\n",
    "x_sample = image.img_to_array(x_test[0])\n",
    "x_sample = np.expand_dims(x_sample, axis=0)\n",
    "\n",
    "# Get CNN features from the sample image using the base CNN model\n",
    "features_test = model.predict(x_sample)\n",
    "\n",
    "# Predict using the classification model\n",
    "new_prediction = classification.predict(features_test)\n",
    "print(\"Predicted class with new model:\", np.argmax(new_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc89645-8f5f-4a74-bc22-2573bdb63d91",
   "metadata": {},
   "source": [
    "### Export Models for codegrade evaluation\n",
    "\n",
    "Export Classification and CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#export your classification model\n",
    "classification.save('classification_model.h5')\n",
    "\n",
    "#export your CNN model\n",
    "model.save('CNN_model.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
